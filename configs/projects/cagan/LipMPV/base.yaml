# How often do you want to log the training stats.
logging_iter: 100
# Number of training epochs.
max_iter: 200000
# Whether to benchmark speed or not.
speed_benchmark: False
image_display_iter: 500
image_save_iter: 5000
snapshot_save_iter: 5000
trainer:
    use_cuda: True
    type: imaginaire.trainers.cagan
    model_average: False
    distribute: False
    amp: O1
    gan_mode: hinge
    loss_weight:
        id: 0.1
        g_fake: 1.0
        f_fake: 1.0
        cycle: 1.0
        real: 1.0
        fake: 1.0
    init:
        type: orthogonal
        gain: 1
gen_opt:
    type: adam
    fused_opt: False
    lr: 0.0002
    adam_beta1: 0.5
    adam_beta2: 0.999
    lr_policy:
        type: constant
dis_opt:
    type: adam
    fused_opt: False
    lr: 0.0002
    adam_beta1: 0.5
    adam_beta2: 0.999
    lr_policy:
        type: constant
gen:
    type: imaginaire.generators.cagan
    nonlinearity: "leakyrelu"

dis:
    type: imaginaire.discriminators.cagan
    nonlinearity: "leakyrelu"

# Data options.
data:
    # Name of this dataset.
    name: lipMPV
    # Which dataloader to use?
    type: imaginaire.datasets.cagan
    # How many data loading workers per GPU?
    num_workers: 8
    train_data_loader_not_distributed: True
    val_data_loader_not_distributed: True
    # Train dataset details.
    train:
        # Input LMDBs.
        roots: D:/workspace/dataset/LIP_MPV_256_192/MPV_256_192/processed2
        # Batch size per GPU.
        batch_size: 16
        # Data augmentations to be performed in given order.
        augmentations:
            # First resize all inputs to this size.
            resize_h: 128
            resize_w: 96

    # Val dataset details.
    val:
        # Input LMDBs.
        roots: D:/workspace/develop/imaginaire/dataset/lipMPV/test
        # Batch size per GPU.
        batch_size: 1
        # If resize_h_w is not given, then it is assumed to be same as crop_h_w.
        augmentations:
            resize_h: 128
            resize_w: 96

test_data:
    # Name of this dataset.
    name: lipMPV
    # Which dataloader to use?
    type: imaginaire.datasets.cagan
    # Validation dataset details.
    test:
        roots: D:/workspace/develop/imaginaire/dataset/lipMPV/test
        # Batch size per GPU.
        batch_size: 1
        # If resize_h_w is not given, then it is assumed to be same as crop_h_w.
        augmentations:
            resize_smallest_side: 1024